{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1c5a17f",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fc53f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from pytorch3d.datasets import ShapeNetCore\n",
    "import torch\n",
    "import torch.nn as nn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f8998a",
   "metadata": {},
   "source": [
    "Some Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09d416cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"../Dataset/ShapeNetCore\"\n",
    "train_ratio = 0.8 # 80% training 20% validation\n",
    "max_points = 700\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e270a755",
   "metadata": {},
   "source": [
    "Setup datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d56e062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['02691156', '02747177', '02773838', '02801938', '02808440', '02818832', '02828884', '02843684', '02871439', '02876657', '02880940', '02924116', '02933112', '02942699', '02946921', '02954340', '02958343', '02992529', '03001627', '03046257', '03085013', '03207941', '03211117', '03261776', '03325088', '03337140', '03467517', '03513137', '03593526', '03624134', '03636649', '03642806', '03691459', '03710193', '03759954', '03761084', '03790512', '03797390', '03928116', '03938244', '03948459', '03991062', '04004475', '04074963', '04090263', '04099429', '04225987', '04256520', '04330267', '04379243', '04401088', '04460130', '04468005', '04530566', '04554684']\n",
      "{'02691156': 0, '02747177': 1, '02773838': 2, '02801938': 3, '02808440': 4, '02818832': 5, '02828884': 6, '02843684': 7, '02871439': 8, '02876657': 9, '02880940': 10, '02924116': 11, '02933112': 12, '02942699': 13, '02946921': 14, '02954340': 15, '02958343': 16, '02992529': 17, '03001627': 18, '03046257': 19, '03085013': 20, '03207941': 21, '03211117': 22, '03261776': 23, '03325088': 24, '03337140': 25, '03467517': 26, '03513137': 27, '03593526': 28, '03624134': 29, '03636649': 30, '03642806': 31, '03691459': 32, '03710193': 33, '03759954': 34, '03761084': 35, '03790512': 36, '03797390': 37, '03928116': 38, '03938244': 39, '03948459': 40, '03991062': 41, '04004475': 42, '04074963': 43, '04090263': 44, '04099429': 45, '04225987': 46, '04256520': 47, '04330267': 48, '04379243': 49, '04401088': 50, '04460130': 51, '04468005': 52, '04530566': 53, '04554684': 54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esfod\\miniconda3\\envs\\py3d\\lib\\site-packages\\pytorch3d\\datasets\\shapenet\\shapenet_core.py:116: UserWarning: The following categories are included in ShapeNetCore ver.2's official mapping but not found in the dataset location ../Dataset/ShapeNetCore: 03710193, 04468005, 03001627, 02958343, 02871439, 04554684, 03797390, 04225987, 03085013, 03636649, 02954340, 02880940, 04530566, 02924116, 03261776, 03938244, 03948459, 03207941, 02747177, 03467517, 03513137, 03928116, 04256520, 03761084, 04379243, 02828884, 03691459, 04401088, 04090263, 04330267, 03624134, 02818832, 03593526, 04460130, 02843684, 02942699, 04074963, 02933112, 04004475, 02691156, 02876657, 03790512, 03325088, 03759954, 04099429, 03337140, 03991062, 02946921, 02773838, 02801938\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "dataset = ShapeNetCore(dataset_path, version=2, load_textures= False)\n",
    "\n",
    "\n",
    "CLASS_SIDS = sorted(dataset.synset_dict.keys())          # ['02808440', '02992529', ...]\n",
    "sid2idx    = {sid: i for i, sid in enumerate(CLASS_SIDS)}  # {'02808440':0, '02992529':1, ...}\n",
    "NUM_CLASSES = len(CLASS_SIDS)\n",
    "\n",
    "\n",
    "\n",
    "print(CLASS_SIDS)\n",
    "print(sid2idx)\n",
    "\n",
    "train_size = int(train_ratio * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13031706",
   "metadata": {},
   "source": [
    "Custom collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a105154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    verts_list = []\n",
    "    labels = []\n",
    "\n",
    "    for sample in batch:\n",
    "        verts = sample['verts']              # [V, 3] (CPU tensor)\n",
    "        n = verts.shape[0]\n",
    "\n",
    "        # --- random sampling to exactly max_points ---\n",
    "        if n >= max_points:\n",
    "            idx = torch.randperm(n)[:max_points]\n",
    "        else:\n",
    "            # sample WITH replacement to reach max_points\n",
    "            idx = torch.randint(0, n, (max_points,))\n",
    "        pts = verts[idx]                     # [max_points, 3]\n",
    "\n",
    "        # (optional but helpful) normalize per shape: center + unit sphere\n",
    "        pts = pts - pts.mean(0, keepdim=True)\n",
    "        scale = pts.norm(p=2, dim=1).max()\n",
    "        pts = pts / (scale + 1e-6)\n",
    "\n",
    "        verts_list.append(pts)\n",
    "        # in collate:\n",
    "        labels.append(sid2idx[sample['synset_id']])  # works if sample['synset_id'] is the ID string\n",
    "\n",
    "    batched_verts = torch.stack(verts_list, dim=0)        # [B, max_points, 3]\n",
    "    labels = torch.tensor(labels, dtype=torch.long)       # [B]\n",
    "    return {'verts': batched_verts, 'labels': labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8ae5b0",
   "metadata": {},
   "source": [
    "Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87f56205",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORKERS = 0\n",
    "PIN_MEMORY = device\n",
    "\n",
    "train_loader =  DataLoader(train_dataset, batch_size = 4, shuffle = True,  collate_fn = custom_collate_fn, num_workers=NUM_WORKERS,pin_memory=PIN_MEMORY)\n",
    "val_loader   =  DataLoader(val_dataset  , batch_size = 4, shuffle = False, collate_fn = custom_collate_fn, num_workers=NUM_WORKERS,pin_memory=PIN_MEMORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7017763",
   "metadata": {},
   "source": [
    "Setup NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3137c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.mlp1 = nn.Sequential(\n",
    "            nn.Conv1d(3,64,1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(2,1)\n",
    "        \n",
    "        \n",
    "        x = self.mlp1(x)\n",
    "        \n",
    "        x = torch.max(x,2)[0]\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82de6ac7",
   "metadata": {},
   "source": [
    "Setup run_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "536096a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, loader, optimizer=None, device=\"cpu\", epoch_tag=\"train\"):\n",
    "    is_train = optimizer is not None\n",
    "    model.train(is_train)\n",
    "\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        x = batch[\"verts\"].to(device, non_blocking=True)   # (B, 700, 3)\n",
    "        y = batch[\"labels\"].to(device, non_blocking=True)  # (B,)\n",
    "\n",
    "        if is_train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        logits = model(x)                  # (B, C)\n",
    "        loss = crit(logits, y)\n",
    "\n",
    "        if is_train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = logits.argmax(dim=1)\n",
    "            total_correct += (preds == y).sum().item()\n",
    "            bs = y.size(0)\n",
    "            total_samples += bs\n",
    "            total_loss += loss.item() * bs\n",
    "\n",
    "    avg_loss = total_loss / max(1, total_samples)\n",
    "    avg_acc  = total_correct / max(1, total_samples)\n",
    "    print(f\"[{epoch_tag}] loss={avg_loss:.4f} | acc={avg_acc:.4f} | n={total_samples}\")\n",
    "    return avg_loss, avg_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9899d19a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m best_val_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,EPOCHS\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 11\u001b[0m     tr_loss, tr_acc   \u001b[38;5;241m=\u001b[39m \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_tag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain/ep\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     val_loss, val_acc \u001b[38;5;241m=\u001b[39m run_epoch(model, val_loader, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, device\u001b[38;5;241m=\u001b[39mdevice, epoch_tag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval/ep\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m val_acc \u001b[38;5;241m>\u001b[39m best_val_acc:\n",
      "Cell \u001b[1;32mIn[7], line 10\u001b[0m, in \u001b[0;36mrun_epoch\u001b[1;34m(model, loader, optimizer, device, epoch_tag)\u001b[0m\n\u001b[0;32m      7\u001b[0m total_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      8\u001b[0m total_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m     11\u001b[0m     x \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverts\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)   \u001b[38;5;66;03m# (B, 700, 3)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     y \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# (B,)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\esfod\\miniconda3\\envs\\py3d\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 734\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    740\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\esfod\\miniconda3\\envs\\py3d\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    789\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    791\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    792\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\esfod\\miniconda3\\envs\\py3d\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\esfod\\miniconda3\\envs\\py3d\\lib\\site-packages\\torch\\utils\\data\\dataset.py:416\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\Users\\esfod\\miniconda3\\envs\\py3d\\lib\\site-packages\\torch\\utils\\data\\dataset.py:416\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\Users\\esfod\\miniconda3\\envs\\py3d\\lib\\site-packages\\pytorch3d\\datasets\\shapenet\\shapenet_core.py:155\u001b[0m, in \u001b[0;36mShapeNetCore.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    151\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_item_ids(idx)\n\u001b[0;32m    152\u001b[0m model_path \u001b[38;5;241m=\u001b[39m path\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshapenet_dir, model[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msynset_id\u001b[39m\u001b[38;5;124m\"\u001b[39m], model[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_id\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_dir\n\u001b[0;32m    154\u001b[0m )\n\u001b[1;32m--> 155\u001b[0m verts, faces, textures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_mesh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m model[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverts\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m verts\n\u001b[0;32m    157\u001b[0m model[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfaces\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m faces\n",
      "File \u001b[1;32mc:\\Users\\esfod\\miniconda3\\envs\\py3d\\lib\\site-packages\\pytorch3d\\datasets\\shapenet_base.py:88\u001b[0m, in \u001b[0;36mShapeNetBase._load_mesh\u001b[1;34m(self, model_path)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_load_mesh\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_path) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple:\n\u001b[1;32m---> 88\u001b[0m     verts, faces, aux \u001b[38;5;241m=\u001b[39m \u001b[43mload_obj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_texture_atlas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_textures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_textures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_textures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtexture_atlas_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtexture_resolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_textures:\n\u001b[0;32m     95\u001b[0m         textures \u001b[38;5;241m=\u001b[39m aux\u001b[38;5;241m.\u001b[39mtexture_atlas\n",
      "File \u001b[1;32mc:\\Users\\esfod\\miniconda3\\envs\\py3d\\lib\\site-packages\\pytorch3d\\io\\obj_io.py:227\u001b[0m, in \u001b[0;36mload_obj\u001b[1;34m(f, load_textures, create_texture_atlas, texture_atlas_size, texture_wrap, device, path_manager)\u001b[0m\n\u001b[0;32m    225\u001b[0m     path_manager \u001b[38;5;241m=\u001b[39m PathManager()\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file(f, path_manager, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_obj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_textures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_textures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_texture_atlas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_texture_atlas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtexture_atlas_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexture_atlas_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtexture_wrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexture_wrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\esfod\\miniconda3\\envs\\py3d\\lib\\site-packages\\pytorch3d\\io\\obj_io.py:597\u001b[0m, in \u001b[0;36m_load_obj\u001b[1;34m(f_obj, data_dir, load_textures, create_texture_atlas, texture_atlas_size, texture_wrap, path_manager, device)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg \u001b[38;5;241m%\u001b[39m texture_wrap)\n\u001b[0;32m    585\u001b[0m (\n\u001b[0;32m    586\u001b[0m     verts,\n\u001b[0;32m    587\u001b[0m     normals,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    594\u001b[0m     mtl_path,\n\u001b[0;32m    595\u001b[0m ) \u001b[38;5;241m=\u001b[39m _parse_obj(f_obj, data_dir)\n\u001b[1;32m--> 597\u001b[0m verts \u001b[38;5;241m=\u001b[39m \u001b[43m_make_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (V, 3)\u001b[39;00m\n\u001b[0;32m    598\u001b[0m normals \u001b[38;5;241m=\u001b[39m _make_tensor(\n\u001b[0;32m    599\u001b[0m     normals,\n\u001b[0;32m    600\u001b[0m     cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m    601\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32,\n\u001b[0;32m    602\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m    603\u001b[0m )  \u001b[38;5;66;03m# (N, 3)\u001b[39;00m\n\u001b[0;32m    604\u001b[0m verts_uvs \u001b[38;5;241m=\u001b[39m _make_tensor(\n\u001b[0;32m    605\u001b[0m     verts_uvs,\n\u001b[0;32m    606\u001b[0m     cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    607\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32,\n\u001b[0;32m    608\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m    609\u001b[0m )  \u001b[38;5;66;03m# (T, 2)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\esfod\\miniconda3\\envs\\py3d\\lib\\site-packages\\pytorch3d\\io\\utils.py:47\u001b[0m, in \u001b[0;36m_make_tensor\u001b[1;34m(data, cols, dtype, device)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m0\u001b[39m, cols), dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 15\n",
    "lr = 3e-4\n",
    "weight_decay = 1e-4\n",
    "\n",
    "model = PointNet(NUM_CLASSES).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr = lr, weight_decay=weight_decay)\n",
    "\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(1,EPOCHS+1):\n",
    "    tr_loss, tr_acc   = run_epoch(model, train_loader, optimizer, device, epoch_tag=f\"train/ep{epoch}\")\n",
    "    val_loss, val_acc = run_epoch(model, val_loader, optimizer=None, device=device, epoch_tag=f\"val/ep{epoch}\")\n",
    "\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_pointnet.pth\")\n",
    "        print(f\"saved new best (val_acc={best_val_acc:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
