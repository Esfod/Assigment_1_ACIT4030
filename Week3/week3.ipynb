{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4827ae6f",
   "metadata": {},
   "source": [
    "Read file mesh to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36c24d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, math, time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "from pytorch3d.datasets import ShapeNetCore\n",
    "from pytorch3d.structures import Meshes, join_meshes_as_batch\n",
    "from pytorch3d.ops import GraphConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b80c7f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_meshes_no_textures(batch):\n",
    "    mesh_list, labels = [], []\n",
    "    for item in batch:  # ShapeNetCore returns dicts per your class\n",
    "        verts, faces = item[\"verts\"], item[\"faces\"]\n",
    "        mesh_list.append(Meshes(verts=[verts], faces=[faces]))\n",
    "        li = LABEL_TO_IDX.get(item.get(\"label\",\"\"),\n",
    "             SYNSET_TO_IDX.get(item.get(\"synset_id\",\"\"), -1))\n",
    "        labels.append(li)\n",
    "    y = torch.tensor(labels, dtype=torch.long)\n",
    "    # Hard assert: all labels mapped\n",
    "    if (y < 0).any() or (y >= NUM_CLASSES).any():\n",
    "        bad = y[(y < 0) | (y >= NUM_CLASSES)]\n",
    "        raise RuntimeError(f\"Collate produced out-of-range labels: {bad.tolist()}\")\n",
    "    return join_meshes_as_batch(mesh_list), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd47b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch_scatter import scatter_mean\n",
    "\n",
    "class MeshGCN(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.g1 = GraphConv(3, 64)\n",
    "        self.g2 = GraphConv(64, 128)\n",
    "        self.g3 = GraphConv(128, 128)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    def forward(self, meshes: Meshes):\n",
    "        x = meshes.verts_packed()\n",
    "        edges = meshes.edges_packed()\n",
    "        m_idx = meshes.verts_packed_to_mesh_idx()\n",
    "\n",
    "        x = torch.relu(self.g1(x, edges))\n",
    "        x = torch.relu(self.g2(x, edges))\n",
    "        x = torch.relu(self.g3(x, edges))\n",
    "\n",
    "        B, D = len(meshes), x.size(1)\n",
    "        device = x.device\n",
    "        sums   = torch.zeros((B, D), device=device)\n",
    "        counts = torch.zeros(B, device=device)\n",
    "        sums.index_add_(0, m_idx, x)\n",
    "        counts.index_add_(0, m_idx, torch.ones_like(m_idx, dtype=x.dtype))\n",
    "        global_feat = sums / counts.clamp_min(1e-6).unsqueeze(-1)\n",
    "\n",
    "        return self.head(global_feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa0ce647",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esfod\\miniconda3\\envs\\py3d\\lib\\site-packages\\pytorch3d\\datasets\\shapenet\\shapenet_core.py:116: UserWarning: The following categories are included in ShapeNetCore ver.2's official mapping but not found in the dataset location ../Dataset/ShapeNetCore: 03948459, 02871439, 03001627, 04530566, 03938244, 03624134, 04074963, 02924116, 03761084, 04460130, 03593526, 03207941, 03797390, 02958343, 02747177, 03710193, 04330267, 04379243, 02828884, 04554684, 03790512, 03513137, 03759954, 04090263, 02773838, 02880940, 03691459, 03991062, 04225987, 02946921, 04256520, 03085013, 02818832, 04401088, 03337140, 02691156, 02933112, 04004475, 04099429, 02801938, 04468005, 02942699, 03636649, 03261776, 02843684, 03928116, 02954340, 03467517, 02876657, 03325088\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pytorch3d.structures.meshes.Meshes object at 0x0000014FBC6C56D0>\n"
     ]
    }
   ],
   "source": [
    "ROOT = \"../Dataset/ShapeNetCore\"      \n",
    "VAL_RATIO = 0.2\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 0\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "dataset = ShapeNetCore(\"../Dataset/ShapeNetCore\", version=2, load_textures=False)                  \n",
    "CLASS_NAMES = sorted(dataset.synset_inv.keys())          # e.g. ['airplane','chair',...]\n",
    "LABEL_TO_IDX = {lbl: i for i, lbl in enumerate(CLASS_NAMES)}\n",
    "SYNSET_TO_IDX = {dataset.synset_inv[lbl]: i for i, lbl in enumerate(CLASS_NAMES)}\n",
    "NUM_CLASSES = len(CLASS_NAMES)  \n",
    "loader = DataLoader(dataset, batch_size=4, collate_fn=collate_meshes_no_textures)\n",
    "\n",
    "meshes,y = next(iter(loader))\n",
    "print(meshes)\n",
    "\n",
    "N = len(dataset)\n",
    "\n",
    "n_val = int(math.ceil(N*VAL_RATIO))\n",
    "n_train = N - n_val\n",
    "\n",
    "train_set, val_set = random_split(dataset, [n_train,n_val], generator=torch.Generator().manual_seed(SEED))\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle = True,\n",
    "                          num_workers=NUM_WORKERS, collate_fn=collate_meshes_no_textures)\n",
    "\n",
    "val_loader = DataLoader(val_set,batch_size=BATCH_SIZE, shuffle = False,\n",
    "                          num_workers=NUM_WORKERS, collate_fn=collate_meshes_no_textures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d67caf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 5 classes:\n",
      "   0: bathtub (02808440)\n",
      "   1: cellphone (02992529)\n",
      "   2: clock (03046257)\n",
      "   3: display (03211117)\n",
      "   4: laptop (03642806)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Detected {NUM_CLASSES} classes:\")\n",
    "for i, name in enumerate(CLASS_NAMES):\n",
    "    print(f\"  {i:2d}: {name} ({dataset.synset_inv[name]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f300bdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_from_logits (logits, targets):\n",
    "    preds = logits.argmax(dim=1)\n",
    "    return (preds == targets).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32e78d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, loader, optimizer=None, device=\"cpu\", epoch_tag=\"train\"):\n",
    "    is_train = optimizer is not None\n",
    "    model.train(is_train)\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "\n",
    "    total_loss = total_acc = 0.0\n",
    "    total_samples = 0\n",
    "    printed = 0\n",
    "\n",
    "    for step, (meshes, y) in enumerate(loader):\n",
    "        # sanity: show per-batch label stats a few times\n",
    "        if printed < 2:\n",
    "            print(f\"[{epoch_tag}] step {step}: y min={int(y.min())}, max={int(y.max())}, size={len(y)}\")\n",
    "            printed += 1\n",
    "\n",
    "        meshes = meshes.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        with torch.set_grad_enabled(is_train):\n",
    "            logits = model(meshes)\n",
    "            loss = crit(logits, y)\n",
    "\n",
    "        if is_train:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        bs = y.size(0)\n",
    "        total_samples += bs\n",
    "        total_loss += loss.item() * bs\n",
    "        total_acc  += (logits.argmax(1) == y).float().sum().item()\n",
    "\n",
    "    if total_samples == 0:\n",
    "        print(f\"[{epoch_tag}] WARNING: no valid samples accumulated -> returning NaN\")\n",
    "        return float(\"nan\"), float(\"nan\")\n",
    "    return total_loss / total_samples, total_acc / total_samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a996445",
   "metadata": {},
   "source": [
    "Check for dataset errors ++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4642fb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total meshes: 3891\n",
      "Total categories: 5\n",
      "Classes (index -> name -> synset):\n",
      "   0: bathtub  (02808440)\n",
      "   1: cellphone  (02992529)\n",
      "   2: clock  (03046257)\n",
      "   3: display  (03211117)\n",
      "   4: laptop  (03642806)\n",
      "\n",
      "Sample[0] keys: ['synset_id', 'model_id', 'verts', 'faces', 'textures', 'label']\n",
      "Sample[0] label string: cellphone\n",
      "Sample[0] synset_id: 02992529\n",
      "Sample[0] verts: torch.Size([11414, 3]) faces: torch.Size([45938, 3])\n",
      "\n",
      "Batch loaded âœ…\n",
      "Batch size (num meshes): 4\n",
      "Packed verts: torch.Size([8568, 3]) | Packed faces: torch.Size([33706, 3])\n",
      "Packed edges: torch.Size([25210, 2])\n",
      "Label IDs: [1, 0, 2, 3]\n",
      "Label names: ['cellphone', 'bathtub', 'clock', 'display']\n",
      "Model forward skipped / error: NameError(\"name 'model' is not defined\")\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from pytorch3d.structures import Meshes, join_meshes_as_batch\n",
    "\n",
    "# --- Build stable class indexers from the dataset you already created ---\n",
    "# dataset.synset_dict: {synset_id -> label}; dataset.synset_inv: {label -> synset_id} (already filtered to loaded cats)\n",
    "CLASS_NAMES = sorted(dataset.synset_inv.keys())  # e.g. ['airplane', 'chair', ...]\n",
    "LABEL_TO_IDX = {lbl: i for i, lbl in enumerate(CLASS_NAMES)}\n",
    "SYNSET_TO_IDX = {dataset.synset_inv[lbl]: i for i, lbl in enumerate(CLASS_NAMES)}  # '03001627' -> class idx\n",
    "\n",
    "def collate_meshes_no_textures(batch):\n",
    "    mesh_list, labels = [], []\n",
    "    for item in batch:  # item is a dict per your class\n",
    "        verts = item[\"verts\"]\n",
    "        faces = item[\"faces\"]\n",
    "        mesh_list.append(Meshes(verts=[verts], faces=[faces]))  # drop textures\n",
    "        # Prefer label string; fallback to synset_id\n",
    "        li = LABEL_TO_IDX.get(item.get(\"label\", \"\"), SYNSET_TO_IDX.get(item.get(\"synset_id\", \"\"), -1))\n",
    "        labels.append(li)\n",
    "    return join_meshes_as_batch(mesh_list), torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "# --- Pretty print dataset summary ---\n",
    "print(\"Total meshes:\", len(dataset))\n",
    "print(\"Total categories:\", len(CLASS_NAMES))\n",
    "print(\"Classes (index -> name -> synset):\")\n",
    "for i, name in enumerate(CLASS_NAMES):\n",
    "    print(f\"  {i:2d}: {name}  ({dataset.synset_inv[name]})\")\n",
    "\n",
    "# --- Peek a single sample ---\n",
    "sample = dataset[0]\n",
    "print(\"\\nSample[0] keys:\", list(sample.keys()))\n",
    "print(\"Sample[0] label string:\", sample[\"label\"])\n",
    "print(\"Sample[0] synset_id:\", sample[\"synset_id\"])\n",
    "print(\"Sample[0] verts:\", sample[\"verts\"].shape, \"faces:\", sample[\"faces\"].shape)\n",
    "\n",
    "# --- Pull one batch and verify shapes + label decoding ---\n",
    "loader_dbg = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_meshes_no_textures)\n",
    "meshes, y = next(iter(loader_dbg))\n",
    "\n",
    "print(\"\\nBatch loaded âœ…\")\n",
    "print(\"Batch size (num meshes):\", len(meshes))\n",
    "print(\"Packed verts:\", meshes.verts_packed().shape, \"| Packed faces:\", meshes.faces_packed().shape)\n",
    "print(\"Packed edges:\", meshes.edges_packed().shape)\n",
    "print(\"Label IDs:\", y.tolist())\n",
    "print(\"Label names:\", [CLASS_NAMES[i] if 0 <= i < len(CLASS_NAMES) else \"<?>\"\n",
    "                      for i in y.tolist()])\n",
    "\n",
    "# --- Extra: quick forward sanity (no grad) if you already defined `model` ---\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        logits = model(meshes.to(next(model.parameters()).device))\n",
    "    print(\"Model forward OK. Logits shape:\", tuple(logits.shape))\n",
    "except Exception as e:\n",
    "    print(\"Model forward skipped / error:\", repr(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "539be9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] step 0: y min=0, max=4, size=8\n",
      "[train] step 1: y min=0, max=3, size=8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      9\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 10\u001b[0m     tr_loss, tr_acc \u001b[38;5;241m=\u001b[39m \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_tag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     va_loss, va_acc \u001b[38;5;241m=\u001b[39m run_epoch(model, val_loader, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, device\u001b[38;5;241m=\u001b[39mdevice, epoch_tag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m     dt \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n",
      "Cell \u001b[1;32mIn[7], line 10\u001b[0m, in \u001b[0;36mrun_epoch\u001b[1;34m(model, loader, optimizer, device, epoch_tag)\u001b[0m\n\u001b[0;32m      7\u001b[0m total_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      8\u001b[0m printed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, (meshes, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# sanity: show per-batch label stats a few times\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m printed \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_tag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] step \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: y min=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(y\u001b[38;5;241m.\u001b[39mmin())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, max=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(y\u001b[38;5;241m.\u001b[39mmax())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(y)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\esfod\\miniconda3\\envs\\py3d\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 734\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    740\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\esfod\\miniconda3\\envs\\py3d\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    789\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    791\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    792\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\esfod\\miniconda3\\envs\\py3d\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\esfod\\miniconda3\\envs\\py3d\\lib\\site-packages\\torch\\utils\\data\\dataset.py:416\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\Users\\esfod\\miniconda3\\envs\\py3d\\lib\\site-packages\\torch\\utils\\data\\dataset.py:416\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\Users\\esfod\\miniconda3\\envs\\py3d\\lib\\site-packages\\pytorch3d\\datasets\\shapenet\\shapenet_core.py:155\u001b[0m, in \u001b[0;36mShapeNetCore.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    151\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_item_ids(idx)\n\u001b[0;32m    152\u001b[0m model_path \u001b[38;5;241m=\u001b[39m path\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshapenet_dir, model[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msynset_id\u001b[39m\u001b[38;5;124m\"\u001b[39m], model[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_id\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_dir\n\u001b[0;32m    154\u001b[0m )\n\u001b[1;32m--> 155\u001b[0m verts, faces, textures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_mesh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m model[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverts\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m verts\n\u001b[0;32m    157\u001b[0m model[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfaces\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m faces\n",
      "File \u001b[1;32mc:\\Users\\esfod\\miniconda3\\envs\\py3d\\lib\\site-packages\\pytorch3d\\datasets\\shapenet_base.py:88\u001b[0m, in \u001b[0;36mShapeNetBase._load_mesh\u001b[1;34m(self, model_path)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_load_mesh\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_path) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple:\n\u001b[1;32m---> 88\u001b[0m     verts, faces, aux \u001b[38;5;241m=\u001b[39m \u001b[43mload_obj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_texture_atlas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_textures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_textures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_textures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtexture_atlas_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtexture_resolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_textures:\n\u001b[0;32m     95\u001b[0m         textures \u001b[38;5;241m=\u001b[39m aux\u001b[38;5;241m.\u001b[39mtexture_atlas\n",
      "File \u001b[1;32mc:\\Users\\esfod\\miniconda3\\envs\\py3d\\lib\\site-packages\\pytorch3d\\io\\obj_io.py:227\u001b[0m, in \u001b[0;36mload_obj\u001b[1;34m(f, load_textures, create_texture_atlas, texture_atlas_size, texture_wrap, device, path_manager)\u001b[0m\n\u001b[0;32m    225\u001b[0m     path_manager \u001b[38;5;241m=\u001b[39m PathManager()\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file(f, path_manager, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_obj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_textures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_textures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_texture_atlas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_texture_atlas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtexture_atlas_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexture_atlas_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtexture_wrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexture_wrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\esfod\\miniconda3\\envs\\py3d\\lib\\site-packages\\pytorch3d\\io\\obj_io.py:611\u001b[0m, in \u001b[0;36m_load_obj\u001b[1;34m(f_obj, data_dir, load_textures, create_texture_atlas, texture_atlas_size, texture_wrap, path_manager, device)\u001b[0m\n\u001b[0;32m    598\u001b[0m normals \u001b[38;5;241m=\u001b[39m _make_tensor(\n\u001b[0;32m    599\u001b[0m     normals,\n\u001b[0;32m    600\u001b[0m     cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m    601\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32,\n\u001b[0;32m    602\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m    603\u001b[0m )  \u001b[38;5;66;03m# (N, 3)\u001b[39;00m\n\u001b[0;32m    604\u001b[0m verts_uvs \u001b[38;5;241m=\u001b[39m _make_tensor(\n\u001b[0;32m    605\u001b[0m     verts_uvs,\n\u001b[0;32m    606\u001b[0m     cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    607\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32,\n\u001b[0;32m    608\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m    609\u001b[0m )  \u001b[38;5;66;03m# (T, 2)\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m faces_verts_idx \u001b[38;5;241m=\u001b[39m \u001b[43m_format_faces_indices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfaces_verts_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;66;03m# Repeat for normals and textures if present.\u001b[39;00m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(faces_normals_idx):\n",
      "File \u001b[1;32mc:\\Users\\esfod\\miniconda3\\envs\\py3d\\lib\\site-packages\\pytorch3d\\io\\obj_io.py:58\u001b[0m, in \u001b[0;36m_format_faces_indices\u001b[1;34m(faces_indices, max_index, device, pad_value)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_format_faces_indices\u001b[39m(faces_indices, max_index: \u001b[38;5;28mint\u001b[39m, device, pad_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     39\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m    Format indices and check for invalid values. Indices can refer to\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m    values in one of the face properties: vertices, textures or normals.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m        ValueError if indices are not in a valid range.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m     faces_indices \u001b[38;5;241m=\u001b[39m \u001b[43m_make_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfaces_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pad_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     63\u001b[0m         mask \u001b[38;5;241m=\u001b[39m faces_indices\u001b[38;5;241m.\u001b[39meq(pad_value)\u001b[38;5;241m.\u001b[39mall(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\esfod\\miniconda3\\envs\\py3d\\lib\\site-packages\\pytorch3d\\io\\utils.py:47\u001b[0m, in \u001b[0;36m_make_tensor\u001b[1;34m(data, cols, dtype, device)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m0\u001b[39m, cols), dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = MeshGCN(NUM_CLASSES).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4,weight_decay=1e-4)\n",
    "EPOCHS = 15\n",
    "\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(1,EPOCHS + 1):\n",
    "    t0 = time.time()\n",
    "    tr_loss, tr_acc = run_epoch(model, train_loader, optimizer=optimizer, device=device, epoch_tag=\"train\")\n",
    "    va_loss, va_acc = run_epoch(model, val_loader, optimizer=None, device=device, epoch_tag=\"val\")\n",
    "    dt = time.time() - t0\n",
    "    \n",
    "    print(f\"[{epoch:02d}/{EPOCHS}] \"\n",
    "          f\"train loss {tr_loss:.4f} acc {tr_acc:.3f} | \"\n",
    "          f\"val loss {va_loss:.4f} acc {va_acc:.3f} | {dt:.1f}s\")\n",
    "    if va_acc > best_val_acc:\n",
    "        best_val_acc = va_acc\n",
    "        torch.save({\"model\":model.state_dict(),\n",
    "                   \"val_acc\":va_acc}, \"meshgcn_best.pt\")\n",
    "        \n",
    "    print(f\"Best val acc: {best_val_acc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
